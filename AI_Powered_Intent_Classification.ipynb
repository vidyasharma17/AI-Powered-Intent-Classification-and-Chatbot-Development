{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSJTsPVKUun"
      },
      "source": [
        "# Fintech Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjhRyvPzKay5"
      },
      "source": [
        "## 1. Overview\n",
        "#### VaultAI is a chatbot for financial services using the BANKING77 dataset. This project demonstrates how to classify intents from the BANKING77 dataset using two different methods:\n",
        "1. **Naive Bayes Classifier** (Traditional ML Approach)\n",
        "2. **Transformer (BERT)** Model (State-of-the-Art NLP)\n",
        "\n",
        "\n",
        "#### **The chabot can:**\n",
        "#### 1. Recognise User Intent\n",
        "#### 2. Extract Entities\n",
        "\n",
        "\n",
        "### **Goal**: Build and compare models to identify intents from user queries and integrate them into a chatbot.\n",
        "\n",
        "### **Objectives:**\n",
        "- #### Train a machine learning model for intent recognition.\n",
        "- #### Implement entity extraction with spaCy.\n",
        "- #### Deploy the chatbot as a REST API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWjrJuTHcgDI"
      },
      "source": [
        "## 2. Data Loading and Preprocessing"
      ]
    },
    {
      "source": [
        "# Install necessary libraries\n",
        "!pip install datasets scikit-learn transformers torch\n",
        "!pip install --upgrade scipy numpy\n",
        "!pip install --upgrade pyarrow\n",
        "!pip install --upgrade datasets\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-cpu"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBlraM0woUlT",
        "outputId": "fc9f3806-a779-45fd-feec-0a7bfdbe99b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires tensorflow>=2.2.0, which is not installed.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.0.0 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.1.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "pytensor 2.26.3 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow-cpu 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.3\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (18.0.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-cpu in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.5.0)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-cpu)\n",
            "  Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.3\n",
            "    Uninstalling numpy-2.1.3:\n",
            "      Successfully uninstalled numpy-2.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires tensorflow>=2.2.0, which is not installed.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.0.0 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.26.3 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c0PjNU3YE02d"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
        "                          Trainer, TrainingArguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcxN_A86KSYk"
      },
      "source": [
        "## 3. Naive Bayes Classifier\n",
        "\n",
        "\n",
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wWaBUrvLhMup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567d6a25-105b-4445-da6a-41513209194a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Disable Weights & Biases logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Load the BANKING77 dataset\n",
        "ds = load_dataset(\"legacy-datasets/banking77\")\n",
        "\n",
        "# Extract text and labels\n",
        "texts = ds[\"train\"][\"text\"]\n",
        "labels = ds[\"train\"][\"label\"]\n",
        "\n",
        "# Map label indices to intent names\n",
        "label_names = ds['train'].features['label'].names\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caeEO7HXUR2m"
      },
      "source": [
        "### Model Training\n",
        "\n",
        "\n",
        "*   Train a Naive Bayes classifier for intent recognition.\n",
        "*   Evaluate the modelâ€™s accuracy and generate a classification report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e8LqVmmhUgqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7179e57-a581-45b7-85af-6218a93fc738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Model Accuracy: 0.79\n",
            "\n",
            "Classification Report (Naive Bayes):\n",
            "                                                  precision    recall  f1-score   support\n",
            "\n",
            "                                activate_my_card       0.63      0.84      0.72        31\n",
            "                                       age_limit       0.96      0.96      0.96        25\n",
            "                         apple_pay_or_google_pay       0.85      0.96      0.90        23\n",
            "                                     atm_support       0.80      0.63      0.71        19\n",
            "                                automatic_top_up       0.93      0.93      0.93        27\n",
            "         balance_not_updated_after_bank_transfer       0.69      0.77      0.73        31\n",
            "balance_not_updated_after_cheque_or_cash_deposit       0.79      0.90      0.84        41\n",
            "                         beneficiary_not_allowed       0.69      0.83      0.75        24\n",
            "                                 cancel_transfer       0.91      0.91      0.91        35\n",
            "                            card_about_to_expire       0.56      1.00      0.71        25\n",
            "                                 card_acceptance       0.00      0.00      0.00        20\n",
            "                                    card_arrival       0.63      0.67      0.65        39\n",
            "                          card_delivery_estimate       0.92      0.48      0.63        25\n",
            "                                    card_linking       0.59      0.91      0.71        22\n",
            "                                card_not_working       0.67      0.35      0.46        23\n",
            "                        card_payment_fee_charged       0.67      0.88      0.76        34\n",
            "                     card_payment_not_recognised       0.49      0.88      0.63        26\n",
            "                card_payment_wrong_exchange_rate       0.79      0.91      0.85        33\n",
            "                                  card_swallowed       1.00      0.25      0.40         8\n",
            "                          cash_withdrawal_charge       0.73      0.97      0.83        31\n",
            "                  cash_withdrawal_not_recognised       0.68      0.88      0.77        26\n",
            "                                      change_pin       0.77      0.96      0.85        24\n",
            "                                compromised_card       0.92      0.50      0.65        22\n",
            "                         contactless_not_working       0.00      0.00      0.00         9\n",
            "                                 country_support       1.00      0.88      0.94        25\n",
            "                           declined_card_payment       0.49      0.69      0.57        26\n",
            "                        declined_cash_withdrawal       0.54      0.89      0.68        28\n",
            "                               declined_transfer       1.00      0.90      0.95        31\n",
            "             direct_debit_payment_not_recognised       0.85      0.89      0.87        37\n",
            "                          disposable_card_limits       0.68      1.00      0.81        30\n",
            "                           edit_personal_details       1.00      0.92      0.96        24\n",
            "                                 exchange_charge       0.93      0.90      0.91        29\n",
            "                                   exchange_rate       0.94      0.65      0.77        26\n",
            "                                exchange_via_app       0.95      0.87      0.91        23\n",
            "                       extra_charge_on_statement       0.90      0.69      0.78        39\n",
            "                                 failed_transfer       0.79      0.77      0.78        30\n",
            "                           fiat_currency_support       0.82      0.90      0.86        20\n",
            "                     get_disposable_virtual_card       0.55      0.63      0.59        19\n",
            "                               get_physical_card       0.94      0.65      0.77        26\n",
            "                              getting_spare_card       1.00      0.82      0.90        22\n",
            "                            getting_virtual_card       0.95      0.62      0.75        32\n",
            "                             lost_or_stolen_card       1.00      0.39      0.56        18\n",
            "                            lost_or_stolen_phone       0.83      0.94      0.88        16\n",
            "                             order_physical_card       0.93      0.50      0.65        26\n",
            "                              passcode_forgotten       1.00      0.60      0.75        30\n",
            "                            pending_card_payment       0.79      0.81      0.80        32\n",
            "                         pending_cash_withdrawal       0.84      0.87      0.85        30\n",
            "                                  pending_top_up       0.76      0.65      0.70        20\n",
            "                                pending_transfer       0.93      0.76      0.84        34\n",
            "                                     pin_blocked       0.96      0.81      0.88        27\n",
            "                                 receiving_money       0.92      1.00      0.96        11\n",
            "                           Refund_not_showing_up       0.84      0.84      0.84        32\n",
            "                                  request_refund       0.90      0.90      0.90        29\n",
            "                          reverted_card_payment?       0.92      0.88      0.90        40\n",
            "                  supported_cards_and_currencies       0.86      0.83      0.85        30\n",
            "                               terminate_account       1.00      0.74      0.85        23\n",
            "                  top_up_by_bank_transfer_charge       0.92      0.71      0.80        17\n",
            "                           top_up_by_card_charge       0.79      0.95      0.86        20\n",
            "                        top_up_by_cash_or_cheque       1.00      0.75      0.86        24\n",
            "                                   top_up_failed       0.76      0.90      0.82        31\n",
            "                                   top_up_limits       1.00      0.70      0.82        20\n",
            "                                 top_up_reverted       0.67      0.86      0.75        21\n",
            "                              topping_up_by_card       0.90      0.56      0.69        16\n",
            "                       transaction_charged_twice       0.93      0.87      0.90        45\n",
            "                            transfer_fee_charged       0.85      0.81      0.83        36\n",
            "                           transfer_into_account       0.52      0.74      0.61        19\n",
            "              transfer_not_received_by_recipient       0.61      0.81      0.70        27\n",
            "                                 transfer_timing       0.63      0.85      0.72        20\n",
            "                       unable_to_verify_identity       0.90      0.43      0.58        21\n",
            "                              verify_my_identity       0.65      0.77      0.71        22\n",
            "                          verify_source_of_funds       0.92      0.88      0.90        25\n",
            "                                   verify_top_up       0.86      0.96      0.91        26\n",
            "                        virtual_card_not_working       0.00      0.00      0.00         9\n",
            "                              visa_or_mastercard       0.96      0.92      0.94        25\n",
            "                             why_verify_identity       0.64      0.70      0.67        20\n",
            "                   wrong_amount_of_cash_received       0.86      0.91      0.89        34\n",
            "         wrong_exchange_rate_for_cash_withdrawal       0.81      0.83      0.82        35\n",
            "\n",
            "                                        accuracy                           0.79      2001\n",
            "                                       macro avg       0.79      0.76      0.75      2001\n",
            "                                    weighted avg       0.80      0.79      0.78      2001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train Naive Bayes Model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred = nb_model.predict(X_test_vec)\n",
        "nb_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Naive Bayes Model Accuracy: {nb_accuracy:.2f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report (Naive Bayes):\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yag6yZOQaya4"
      },
      "source": [
        "## 4. Transformer (BERT)\n",
        "\n",
        "### Preprocessing and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8R9TE6SCdUoH"
      },
      "outputs": [],
      "source": [
        "# Tokenizer for BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize datasets\n",
        "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(X_test, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "class BankingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = BankingDataset(train_encodings, y_train)\n",
        "test_dataset = BankingDataset(test_encodings, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPjWzY-ArIpl"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LaBDeyyGrKZl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "71fcf39e-3ab6-4cec-e4ce-5c454c1c7a64"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3920' max='4002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3920/4002 1:54:10 < 02:23, 0.57 it/s, Epoch 1.96/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.743025</td>\n",
              "      <td>0.839080</td>\n",
              "      <td>0.832607</td>\n",
              "      <td>0.862095</td>\n",
              "      <td>0.839080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4002' max='4002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4002/4002 1:58:37, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.743025</td>\n",
              "      <td>0.839080</td>\n",
              "      <td>0.832607</td>\n",
              "      <td>0.862095</td>\n",
              "      <td>0.839080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.386400</td>\n",
              "      <td>0.411039</td>\n",
              "      <td>0.889555</td>\n",
              "      <td>0.887394</td>\n",
              "      <td>0.898966</td>\n",
              "      <td>0.889555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4002, training_loss=1.3270114467240524, metrics={'train_runtime': 7123.031, 'train_samples_per_second': 2.247, 'train_steps_per_second': 0.562, 'total_flos': 132677737400064.0, 'train_loss': 1.3270114467240524, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Use a smaller model (DistilBERT) for faster training\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_names))\n",
        "\n",
        "# Define optimized training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,  # Slightly higher learning rate for faster convergence\n",
        "    per_device_train_batch_size=4,  # Reduced batch size for CPU efficiency\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,  # Reduced number of epochs for faster training\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"no\",  # Avoid intermediate checkpoint saves\n",
        "    logging_steps=500,  # Log less frequently\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Define metrics for evaluation\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# Initialize Trainer with dynamic padding\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc5psn-ywnPu"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ptrR-OiLwTjs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "83f98ec8-1b6d-4313-8902-e8c48306c878"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='251' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [251/251 02:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Model Accuracy: 0.89\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fintech_bert_model/tokenizer_config.json',\n",
              " './fintech_bert_model/special_tokens_map.json',\n",
              " './fintech_bert_model/vocab.txt',\n",
              " './fintech_bert_model/added_tokens.json',\n",
              " './fintech_bert_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## Evaluate the BERT Model\n",
        "results = trainer.evaluate(test_dataset)\n",
        "bert_accuracy = results[\"eval_accuracy\"]\n",
        "print(f\"Transformer Model Accuracy: {bert_accuracy:.2f}\")\n",
        "\n",
        "# Save Model and Tokenizer\n",
        "model.save_pretrained(\"./fintech_bert_model\")\n",
        "tokenizer.save_pretrained(\"./fintech_bert_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Compare Naive Bayes and BERT\n"
      ],
      "metadata": {
        "id": "pIXaBthDSBlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Naive Bayes Accuracy: {nb_accuracy:.2f}\")\n",
        "print(f\"BERT Accuracy: {bert_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ1CnHd9PZ2f",
        "outputId": "75ec6142-fd41-4e1b-9725-206e68af7291"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.79\n",
            "BERT Accuracy: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Define Chatbot Logic"
      ],
      "metadata": {
        "id": "X4baumUWSPGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./fintech_bert_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fintech_bert_model\")\n",
        "\n",
        "#Define Chatbot response logic\n",
        "def predict_intent(user_input):\n",
        "    inputs = tokenizer(user_input, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    outputs = model(**inputs)\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return predicted_label\n",
        "\n",
        "    # Full label-to-intent mapping (example for the first few intents)\n",
        "label_to_intent = {\n",
        "    0: \"activate_my_card\",\n",
        "    1: \"age_limit\",\n",
        "    2: \"apple_pay_or_google_pay\",\n",
        "    # Add all remaining labels up to 76\n",
        "}\n",
        "\n",
        "# Responses for each intent\n",
        "responses = {\n",
        "    \"activate_my_card\": \"To activate your card, go to the app's settings and follow the activation instructions.\",\n",
        "    \"age_limit\": \"The age limit for this service is 18 years or older.\",\n",
        "    \"apple_pay_or_google_pay\": \"Yes, we support Apple Pay and Google Pay. You can add your card via their respective apps.\",\n",
        "    # Add responses for all other intents\n",
        "}\n",
        "\n",
        "# Default response for unknown intents\n",
        "default_response = \"Sorry, I didn't understand your request. Can you rephrase?\"\n",
        "\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    try:\n",
        "        label = predict_intent(user_input)\n",
        "        intent = label_to_intent.get(label, \"unknown_intent\")\n",
        "        response = responses.get(intent, default_response)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return \"There was an error processing your request. Please try again later.\""
      ],
      "metadata": {
        "id": "b-jqbAzZSlrP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Chatbot Integration\n",
        "\n",
        "The chatbot uses Flask to expose a REST API for interaction.\n",
        "\n",
        "- **Endpoint**: `/chat`\n",
        "- **HTTP Method**: POST\n",
        "- **Request Payload**:\n",
        "    ```json\n",
        "    {\"text\": \"How do I activate my card?\"}\n",
        "    ```\n",
        "- **Response**:\n",
        "    ```json\n",
        "    {\"response\": \"To activate your card, go to the app's settings and follow the activation instructions.\"}\n",
        "    ```"
      ],
      "metadata": {
        "id": "hatkv8MNW1BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    user_input = request.json.get(\"text\", \"\")\n",
        "    response = chatbot_response(user_input)\n",
        "    return jsonify({\"response\": response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU1UDu23W8R9",
        "outputId": "32dc4ab5-9c14-4f6f-deb8-398f86a3ad53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Evaluation Results\n",
        "\n",
        "| **Model**       | **Accuracy** | **Precision** | **Recall** | **F1-Score** |\n",
        "|------------------|--------------|---------------|------------|--------------|\n",
        "| Naive Bayes      | 79%          | 78%           | 79%        | 78%          |\n",
        "| BERT             | 89%          | 88%           | 89%        | 88%          |\n",
        "\n",
        "### **Observations**:\n",
        "- **Naive Bayes**: Lightweight, suitable for resource-constrained environments.\n",
        "- **BERT**: Superior accuracy and contextual understanding, recommended for production use."
      ],
      "metadata": {
        "id": "Q5NbCNAVi-Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Recommendations\n",
        "- Use BERT for production applications requiring high accuracy and contextual understanding.\n",
        "- Naive Bayes is suitable for lightweight tasks or resource-limited scenarios.\n",
        "- Enhance the chatbot by adding more intents and responses for improved usability."
      ],
      "metadata": {
        "id": "utSltevnjODj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}